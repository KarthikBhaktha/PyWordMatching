{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keyword Matching in python\n",
    "When you apply for a job online through an employer's website, the resume which you upload usually goes through an ATS(Applicant Tracking System), it is the first step a company employs to filter out resumes, given the amount of applicants applying for a given position is enormous, makes it difficult for the hiring manager of that comapny to browse and review all the appllications submitted.<br>\n",
    "Hence the ATSs are usually configured in a way that it will browse through your resume looking for certain predefined keywords and tries to find<br>those in the resume. It will then forward that resume to the hiring manager if the keywords found in that resume is above the set limit.<br> For example: If the job description has about 20 technical keywords, the limit set on the ATS is 10, if the applicants resume has more than 10 matching keyword then it wil be forwarded to the hiring manager and the other reumes will stay in the database and will be scanned again when a new job has opened up and the hiring manager is looking for candidates, the application goes through the same proccess again.\n",
    "<br>\n",
    "## The purpose of the project is:\n",
    "### - SCAN\n",
    "### - MATCH\n",
    "### - FILTER\n",
    "### - RESULT\n",
    "Goal is to scan our resumes against the job description and pull out technical keywords by filtering them out using a set of keywords<br>and returning the list of keywords which can be used to alter the resume in order to tailor the resume based on the list of keywords found"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the libraries\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import string\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pyplot as plt; plt.rcdefaults()\n",
    "import numpy as np\n",
    "\n",
    "#Magic command required to display graphs in notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading and storing the text files as a set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def file(path,name):\n",
    "    with open(path, 'r', encoding=\"utf-8-sig\") as f1:\n",
    "        stop_words = set(stopwords.words('english'))\n",
    "        contents_f1 = f1.read()\n",
    "        tokenized_contents_f1 = word_tokenize(contents_f1)\n",
    "        tokenized_contents_f1 = filter(lambda x: x not in string.punctuation, tokenized_contents_f1)\n",
    "        cleaned_content_f1 = filter(lambda x: x not in stop_words, tokenized_contents_f1)\n",
    "        filtered_content_f1 = [y.strip().lower() for x in cleaned_content_f1 for y in x.split(\" \")]\n",
    "        set_of_job_skills = set(filtered_content_f1)\n",
    "        set_of_job_skills.difference_update({'' '','to','into','/','it','of','for','and','on','a','the','in','desk'})\n",
    "        print('\\n \\t This list below contains {name}:'.format(name=name),'\\n\\n',set_of_job_skills,'\\n\\n', '\\t The length of the set is: {length}'.format(length= len(set_of_job_skills)))\n",
    "    return set_of_job_skills\n",
    "  #here you load your text files that needs to be scanned  \n",
    "list_of_skills = set(file('C:\\\\Users\\\\kats1\\\\Desktop\\\\Blacboard\\\\Python\\\\list_of_skills.txt','list of skills'))\n",
    "myskills = set(file('C:\\\\Users\\\\kats1\\\\Desktop\\\\Blacboard\\\\Python\\\\skills.txt','my skills'))\n",
    "job_desc = set(file('C:\\\\Users\\\\kats1\\\\Desktop\\\\Blacboard\\\\Python\\\\jobdesc.txt','job description'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing the file here\n",
    "-using the and operator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare(set1,set2)    \n",
    "    comp = set1 & set2\n",
    "    #myskill_job_list = job_list & myskills\n",
    "    m = len(job_list)\n",
    "    n = len(myskill_job_list)\n",
    "    print(\"This is a comparison between jobdesc and list of skills: \\n\",job_list,\"\\n\")\n",
    "    print(\"The length of the list above is: \",m)\n",
    "    print(\"This is a comparison between myskills and the joblist: \\n\",myskill_job_list,'\\n')\n",
    "    print(\"The length of the list above is: \",n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the scoring pattern\n",
    "-In order to generate a bar chart, I used the length of the set as a mean to generate a numpy<br>\n",
    "-If the number of MMy Skills is more than half of the Job SKills it means that its a good match<br>\n",
    "-You can edit the resume accordingly\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "objects = ('Job Skills', 'My Skills')\n",
    "y_pos = np.arange(len(objects))\n",
    "performance = [m,n]\n",
    " \n",
    "plt.bar(y_pos, performance, align='center', alpha=1)\n",
    "plt.xticks(y_pos, objects)\n",
    "plt.ylabel('Number of keywords')\n",
    "plt.title('Comparing Keywords')\n",
    " \n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
