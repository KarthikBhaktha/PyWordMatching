{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Purpose:\n",
    "- To scan the text file (my Resume in this case)<br>\n",
    "- To scan the text file (Job Description and resposibilities) that contains matching key words<br>\n",
    "- Return the count of matched keywords and return the missing keywords<br>\n",
    "- Use a list of technical keywords to extract the key words from the job text file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use nltk to fetch stopwords.\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import string\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filtering the text files.\n",
    "## Things to be done:\n",
    "- Converted the source files into CSV using Notepad++<br>\n",
    "- Open and read the csv files<br>\n",
    "- Tokenize the content (Converting each word & characters into individual tokens)<br>\n",
    "- Removing the punctuations (, . - \"white spaces\")<br>\n",
    "- Removing Stopwords (a, the , and, an , is........): Here you can find the entire list of stopwords https://gist.github.com/sebleier/554280<br>\n",
    "- Removing the duplicate elements from the list for more accuracy.<br>\n",
    "- Converting the elements into sets (aoids duplication by default)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'css3', '', 'develop', 'data visualization', 'prioratization', 'teamwork', 'entity-relationship', 'requirement elicitation.', 'design', 'anaconda', 'plot', 'jupyterlab', 'web design', 'spyder', 'identify user needs', 'mysql', 'use-cases', 'php', 'data science', 'logical data models', 'analyze', 'ipython notebook', 'troubleshooting', 'data storage', 'state diagram', 'scenarios', 'clean', 'python', 'data', 'web development', 'project development', 'analytics', 'critical thinking', 'relational database', 'identifying', 'surveys', 'team', 'data modelling', 'articulate', 'prototyping', 'numpy', 'pandas', 'matplotlib', 'data models', 'uml diagrams', 'html5', 'data analysis', 'leadreship', 'sequence diagram', 'tableau', 'user requirement', 'analytical thinking', 'business intelligence', 'oracle sql', 'interpersonal communication', 'database', 'mysq', 'sql'}\n",
      "You have 58 skills\n"
     ]
    }
   ],
   "source": [
    "#using content mmanager to open and read file\n",
    "#converted the text file into csv file at the source using Notepad++\n",
    "#remmoved all the unecessary code for optimization.\n",
    "with open(r'C:\\Users\\kats1\\Desktop\\Blacboard\\Python\\skills.csv', 'r', encoding=\"utf-8-sig\") as f:\n",
    "    myskills = f.readlines()\n",
    "    #converting mall the string in the list to lowercase\n",
    "    #all the strings are converted to lowercase and split at ','.\n",
    "    list_of_myskills = [y.strip().lower() for x in myskills for y in x.split(',')]\n",
    "    set_of_myskills = set(list_of_myskills)\n",
    "    #print(type(nodup_filtered_content))\n",
    "\n",
    "#removing the empty element \n",
    "set_of_myskills.pop()\n",
    "print(set_of_myskills)\n",
    "len_mySkills = len(set_of_myskills)\n",
    "print(\"You have {skills} skills\".format(skills=len_mySkills))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'r', 'opportunities', 'scalable', 'develop', 'critical', 'root', 'using', 'analyses', 'development', 'fuel', 'preferred', 'operations', 'growth', 'teams', 'communication', 'marketing', '2+', 'provide', 'cross-functional', 'python', 'product', 'recommendations', 'cause', 'work', 'communicate', 'similar', 'fields', 'collaborate', 'ability', 'sql', 'code', 'years', 'analytical', 'ways', 'committed', 'perform', 'write', 'engineering', 'group', 'decisions', 'consulting', 'management', 'build', 'frameworks', 'sales', 'degrees', 'manner', 'strategic', 'mathematics', 'high', 'dashboards', 'intelligence', 'passionate', 'facilitate', 'happiness', 'join', 'skills', 'people', 'degree', 'believe', 'results', 'power', 'data', 'variance', 'b2b', 'stem', 'future', 'organization', 'users', 'strong', 'trends', 'plus', 'senior', 'inherently', 'efficient', 'business', 'behind', 'identify', 'science', 'technology', 'new', 'excel', 'benchmarks', 'drive', 'unlock', 'experience', 'saas', 'monitor', 'excellent', 'initiatives', 'finance', 'self-driven', 'self-guided', 'regularly', 'mentioned', 'modify', 'maintain', 'economics', 'background', 'metrics', 'bachelors', 'key', 'curious', 'reports', 'delivering'}\n",
      "There are 105 skills in the job requirement list\n"
     ]
    }
   ],
   "source": [
    "#open and read the text file\n",
    "with open(r'C:\\Users\\kats1\\Desktop\\Blacboard\\Python\\jobdesc.txt', 'r', encoding=\"utf-8-sig\") as f1:\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    contents_f1 = f1.read()\n",
    "    tokenized_contents_f1 = word_tokenize(contents_f1)\n",
    "    #removing the punctuations\n",
    "    tokenized_contents_f1 = filter(lambda x: x not in string.punctuation, tokenized_contents_f1)\n",
    "    #removing stopwords \n",
    "    cleaned_content_f1 = filter(lambda x: x not in stop_words, tokenized_contents_f1)\n",
    "    #all the strings are converted to lowercase and split at ','\n",
    "    filtered_content_f1 = [y.strip().lower() for x in cleaned_content_f1 for y in x.split(',')]\n",
    "    #getting rid of the duplicate elements in the list\n",
    "    set_of_job_skills = set(filtered_content_f1)\n",
    "    print(set_of_job_skills)\n",
    "    print(\"There are {skills} skills in the job requirement list\".format( skills= len(set_of_job_skills)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Uploading the text file to which the comparison needs to be made.\n",
    "- Performing the similar operation which is done above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'', 'application and server monitoring tools', 'data visualization tools', 'teamwork', 'development', 'documentation', 'operating systems', 'reporting', 'information systems', 'agile development', 'design', 'file systems', 'design and build database management system', 'operations', 'logical thinking', 'user-centered design', 'cloud systems administration', 'network operations', 'communication', 'emerging technologies', 'web applications', 'problem solving', 'analyze and recommend database improvements', 'design principles', 'migrating existing workloads into cloud systems', 'open source technology integration', 'ui / ux', 'software quality assurance (qa)', 'critical thinking', 'software engineering', 'touch input navigation', 'self starting', 'data imports', 'develop and test methods to synchronize data', 'data mining', 'cloud based visualizations', '\"install', 'self motivated', 'wireframes', 'programming', 'linux', 'developer', 'presentation', 'data analytics', 'cloud platforms', 'code', 'servers', 'configure database software', 'product development', 'team building', 'deployment automation tools', 'analytical', 'team oriented', 'front end design', 'continuous deployment', 'software', 'applications', 'implementation', 'motivation', 'microsoft office', 'solid understanding of companyâ€™s data needs', 'identify user needs', 'implement backup and recovery plan', 'messaging', 'coding', 'cloud management tools', 'process flows', 'management', 'data storage', 'utilizing cloud automation tools', 'support', 'user interaction diagrams', 'user flows', 'deployment of cloud services', 'web development', 'networking', 'responsive design', 'analytics', 'assign passwords and maintain database access', 'user testing', 'product training', 'internet', 'review existing solutions', 'business intelligence', 'information architecture', 'optimize queries on live data', 'cloud scalability', 'software development', 'user research', 'user interface', 'usability', 'security', 'work independently', 'networks', 'it optimization', 'tech skills', 'solid project management capabilities', 'it soft skills', 'google analytics', 'interaction design', 'data strategy', 'information design', 'it security', 'mobile applications', 'time management', 'web design', 'hardware', 'deploying applications in a cloud environment', 'content strategy', 'troubleshooting', 'tablets', 'integrating security protocols with cloud design', 'it solutions', 'business analytics', 'prototyping methods', 'design specifications', 'project management', 'analyze impact of database changes to the business', 'product management', 'data visualizations', 'data modeling', 'testing', 'configuration management', 'continually review processes for improvement', 'agile project methodology', 'storage', 'data analysis', 'organization', 'technical support', 'cloud services', 'technical writing', 'cloud hosting services', 'strong technical and interpersonal communication', 'continuous integration', 'database', 'integrated technologies', 'and merge databases \"', 'visual design', 'application development', 'develop and secure network structures', 'web analytics', 'audit database access and requests', 'technology', 'design tools', 'product support', 'web technologies', 'configuration', 'cloud maintenance tasks', 'content management', 'tools', 'attention to detail', 'product design', 'computer', 'user experience', 'data intelligence', 'data science', 'optimizing user experiences', 'help desk', 'database administration', 'amazon web services (aws)', 'desktop support', 'flexibility', 'maintain', 'design prototypes', 'business process modeling', 'metrics', 'troubleshooting break-fix scenarios', 'leadership', 'optimizing website performance', 'research emerging technology', 'search engine optimization (seo)', 'interaction flows', 'it support', 'systems software', 'installation', 'apis', 'virtualization', 'methodology', 'architecture', 'languages', 'repairs', 'customer support', 'training', 'big data', 'cloud applications'}\n",
      "The number of elements in this list are: 185\n"
     ]
    }
   ],
   "source": [
    "#open and read by line from the text file\n",
    "with open(r'C:\\Users\\kats1\\Desktop\\Blacboard\\Python\\list_of_skills.csv', 'r') as f2:\n",
    "    #using readlines() instead of read(), becasue it reads line by line (each line as a string obj in the python list)\n",
    "    contents_f2 = f2.readlines()\n",
    "    #converting mall the string in the list to lowercase\n",
    "    list_of_skills = [y.strip().lower() for x in contents_f2 for y in x.split(',')]\n",
    "    #converting into sets\n",
    "    set_of_skills = set(list_of_skills)\n",
    "print(set_of_skills)\n",
    "print(\"The number of elements in this list are: {mthd}\".format(mthd = len(set_of_skills)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comaparing the 2 sets.\n",
    "### Goal:\n",
    "- compare the sets and return a set which contains the matching elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to compare 2 sets.\n",
    "def set_compare(set1,set2):\n",
    "    comp = set(set1 & set2)\n",
    "    if(comp):        \n",
    "         print(\"THe match is: \", comp)\n",
    "    else:\n",
    "        print(\"No matching skills\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THe match is:  {'maintain', 'operations', 'metrics', 'organization', 'analytical', 'technology', 'communication', 'development', 'management', 'code'}\n",
      "THe match is:  {'develop', 'data', 'sql', 'python'}\n",
      "THe match is:  {'', 'web design', 'data analysis', 'identify user needs', 'web development', 'teamwork', 'data science', 'analytics', 'critical thinking', 'business intelligence', 'troubleshooting', 'data storage', 'database', 'design'}\n"
     ]
    }
   ],
   "source": [
    "    #comparing skills for the job with the list of skills\n",
    "    set_compare(set_of_job_skills,set_of_skills)\n",
    "    \n",
    "    #Comparing my skills with the skills required for the job \n",
    "    compare2 = set_compare(set_of_myskills,set_of_job_skills)\n",
    "    \n",
    "    #cmparing my skills with the list of skills\n",
    "    compare3 = set_compare(set_of_myskills,set_of_skills)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The scoring system.\n",
    "- it needs to return a percentage match after displaying the matched elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NoneType"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(compare1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
