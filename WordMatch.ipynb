{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Purpose:\n",
    "- To scan the text file (my Resume in this case)<br>\n",
    "- To scan the text file (Job Description and resposibilities) that contains matching key words<br>\n",
    "- Return the count of matched keywords and return the missing keywords<br>\n",
    "- Use a list of technical keywords to extract the key words from the job text file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use nltk to fetch stopwords.\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import string\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning skills text file.\n",
    "## Things to be done:\n",
    "- Open and read the text file\n",
    "- Tokenize the content (Converting each word & characters into individual tokens)<br>\n",
    "- Removing the punctuations (, . - \"white spaces\")<br>\n",
    "- Removing Stopwords (a, the , and, an , is........): Here you can find the entire list of stopwords https://gist.github.com/sebleier/554280<br>\n",
    "- Removing the duplicate elements from the list for more accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mysql', 'matplotlib', 'ipython', 'data', 'requirement', 'sequence', 'prioratization', 'prototyping', 'analysis', 'surveys', 'database', 'html5', 'pandas', 'css3', 'mysq', 'analyze', 'scenarios', 'diagrams', 'plot', 'oracle', 'identifying', 'logical', 'project', 'tableau', 'sql', 'state', 'anaconda', 'relational', 'development', 'develop', 'notebook', 'spyder', 'teamwork', 'visualization', 'diagram', 'leadreship', 'uml', 'models', 'numpy', 'use-cases', 'php', 'team', 'elicitation.', 'user', 'design', 'python', 'jupyterlab', 'entity-relationship', 'articulate', 'clean'}\n"
     ]
    }
   ],
   "source": [
    "#using content mmanager to open and read file\n",
    "#converted the text file into csv file\n",
    "with open(r'C:\\Users\\kats1\\Desktop\\Blacboard\\Python\\skills.csv', 'r', encoding=\"utf-8-sig\") as f:\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    contents = f.read().lower()\n",
    "    tokenized_contents = word_tokenize(contents)\n",
    "    #removing the punctuations\n",
    "    tokenized_contents = filter(lambda x: x not in string.punctuation, tokenized_contents)\n",
    "    #removing stopwords \n",
    "    cleaned_content = filter(lambda x: x not in stop_words, tokenized_contents)\n",
    "    filtered_content = list(cleaned_content)\n",
    "    #getting rid of the duplicate elements in the list\n",
    "    #converted into a set of elements (easier to perform comaprison between 2 sets)\n",
    "    set_of_myskills = set(filtered_content)\n",
    "    #print(type(nodup_filtered_content))\n",
    "print(set_of_myskills)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Uploading the text file to which the comparison needs to be made.\n",
    "- Performing the similar operation which is done above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#open and read the text file\n",
    "with open(r'C:\\Users\\kats1\\Desktop\\Blacboard\\Python\\jobdesc.txt', 'r', encoding=\"utf-8-sig\") as f1:\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    contents_f1 = f1.read()\n",
    "    tokenized_contents_f1 = word_tokenize(contents_f1)\n",
    "    #removing the punctuations\n",
    "    tokenized_contents_f1 = filter(lambda x: x not in string.punctuation, tokenized_contents_f1)\n",
    "    #removing stopwords \n",
    "    cleaned_content_f1 = filter(lambda x: x not in stop_words, tokenized_contents_f1)\n",
    "    filtered_content_f1 = list(cleaned_content_f1)\n",
    "    #getting rid of the duplicate elements in the list\n",
    "    nodup_filtered_content_f1 = list(set(filtered_content_f1))\n",
    "    print(type(nodup_filtered_content_f1))\n",
    "print(nodup_filtered_content_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comaparing the 2 lists.\n",
    "### Goal:\n",
    "- compare the lists and return a list which contains the matching elements and the ones that are not in the 1st list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# writing a funtiion that returns the common elements after comparung the 2 lists.\n",
    "def compare(list1 , list2):\n",
    "    for elements in list1:\n",
    "        if elements in list2:\n",
    "            return elements\n",
    "            \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare(nodup_filtered_content,nodup_filtered_content_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'assign passwords and maintain database access,agile development,agile project methodology,amazon web services (aws),analytics,analytical,analyze and recommend database improvements,analyze impact of database changes to the business,audit database access and requests,apis,application and server monitoring tools,applications,application development,attention to detail,architecture,big data,business analytics,business intelligence,business process modeling,cloud applications,cloud based visualizations,cloud hosting services,cloud maintenance tasks,cloud management tools,cloud platforms,cloud scalability,cloud services,cloud systems administration,code,coding,computer,communication,configure database software,configuration,configuration management,content strategy,content management,continually review processes for improvement ,continuous deployment,continuous integration,critical thinking,customer support,database,data analysis,data analytics,data imports,data imports,data intelligence,data mining,data modeling,data science,data strategy,data storage,data visualization tools,data visualizations,database administration,deploying applications in a cloud environment,deployment automation tools,deployment of cloud services,design,desktop support,design,design and build database management system,design principles,design prototypes,design specifications,design tools,develop and secure network structures,develop and test methods to synchronize data ,developer,development,documentation,emerging technologies,file systems,flexibility,front end design,google analytics,hardware,help desk,identify user needs ,implement backup and recovery plan ,implementation,information architecture,information design,information systems,interaction design,interaction flows,\"install, maintain, and merge databases \",installation,integrated technologies,integrating security protocols with cloud design,internet,it optimization,it security,it soft skills,it solutions,it support,languages,logical thinking,leadership,linux,management,messaging,methodology,metrics,microsoft office,migrating existing workloads into cloud systems,mobile applications,motivation,networks,network operations,networking,open source technology integration,operating systems,operations,optimize queries on live data,optimizing user experiences,optimizing website performance,organization,presentation,programming,problem solving,process flows,product design,product development,prototyping methods,product development,product management,product support,product training,project management,repairs,reporting,research emerging technology,responsive design,review existing solutions,search engine optimization (seo),security,self motivated,self starting,servers,software,software development,software engineering,software quality assurance (qa),solid project management capabilities ,solid understanding of companyâ€™s data needs ,storage,strong technical and interpersonal communication ,support,systems software,tablets,team building,team oriented,teamwork,technology,tech skills,technical support,technical writing,testing,time management,tools,touch input navigation,training,troubleshooting,troubleshooting break-fix scenarios,user research,user testing,usability,user-centered design,user experience,user flows,user interface,user interaction diagrams,user research,user testing,ui / ux,utilizing cloud automation tools,virtualization,visual design,web analytics,web applications,web development,web design,web technologies,wireframes,work independently,'}\n"
     ]
    }
   ],
   "source": [
    "#open and read by line from the text file\n",
    "with open(r'C:\\Users\\kats1\\Desktop\\Blacboard\\Python\\list_of_skills.csv', 'r') as f2:\n",
    "    #using readlines() instead of read(), becasue it reads line by line instead of word by wor\n",
    "    contents_f2 = f2.readlines()\n",
    "    #converting mall the string in the list to lowercase\n",
    "    list_of_skills = map(lambda x: x.lower(), contents_f2)\n",
    "    #converting into sets\n",
    "    set_of_skills = set(list_of_skills)\n",
    "    print(set_of_skills)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare(list_of_skills,nodup_filtered_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
