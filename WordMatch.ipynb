{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Purpose:\n",
    "- To scan the text file (my Resume in this case)<br>\n",
    "- To scan the text file (Job Description and resposibilities) that contains matching key words<br>\n",
    "- Return the count of matched keywords and return the missing keywords<br>\n",
    "- Use a list of technical keywords to extract the key words from the job text file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\kats1\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#use nltk to fetch stopwords.\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import string\n",
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning skills text file.\n",
    "## Things to be done:\n",
    "- Open and read the text file\n",
    "- Tokenize the content (Converting each word & characters into individual tokens)<br>\n",
    "- Removing the punctuations (, . - \"white spaces\")<br>\n",
    "- Removing Stopwords (a, the , and, an , is........): Here you can find the entire list of stopwords https://gist.github.com/sebleier/554280<br>\n",
    "- Removing the duplicate elements from the list for more accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['arranged', 'definitions', 'essential', '3', 'Entity-Relationship', 'developing', 'Performed', 'Relationship', 'chart', 'New', 'tasks', 'made', 'Matplotlib', 'development', 'iPython', 'functionalities', 'CSS3', 'needs', 'website', 'UML', 'descriptions', 'Prepared', 'surveys', 'Jupyterlab', 'Entity', 'requirement', 'Data', 'operations', 'prototyping', 'USA', 'interactions', 'Clean', 'Designed', 'top', 'displays', 'requirements', 'Apache', 'real', 'attributes', 'tables', 'sales', 'four', 'life', 'data', 'text', 'regions', 'Customer', 'elicitation', 'MySQL', 'HTML5', 'sequence', 'Built', 'analyze', 'based', 'Oracle', 'extension', 'Proficiency', 'set', 'identifying', 'Gathered', 'articulated', 'PHP', 'Map', 'Creately', 'records', 'analysis', 'count', 'relational', 'refined', 'words', 'shows', 'Spyder', 'backend', 'NumPy', 'recurring', 'business', 'age', 'track', 'outputs', 'Scenarios', 'Jupyter', 'management', 'state', 'diagrams', 'interviews', 'segregated', 'Python', 'Created', 'citizens', 'detailed', 'number', 'object', 'Jersey', 'database', 'Tableau', 'Lead', 'supporting', 'find', 'using', 'included', 'employee', 'team', 'file', 'Vendor', 'EZ-Pass', 'Chart', 'Familiar', 'designing', 'scenarios', 'Bar', 'php', 'Employee', 'Develop', 'client', 'Diagram', 'stored', 'Logical', 'storing', 'actors', 'profits', 'python', 'contained', 'info', 'gender', 'hobby', 'system', 'area', 'Pandas', 'dataset', 'Anaconda', 'Use-Cases', 'three', 'Analyzed', 'XAMPP', 'must', 'company', 'event', 'store', 'user', 'Models', 'use-cases', 'elements', 'public', 'representative', 'Online', 'meetings', 'relations', 'Notebook', 'documents', 'specify', 'Initial', 'Visualization', 'person', 'Developed', 'groups', 'SQL', 'Creator', 'use', 'cases', 'MySql', 'prioritized', 'containing', 'project', 'plot', 'relationships', 'Analysis', 'managed', 'involved', 'visuals', 'Design', 'word', 'diagram', 'web', 'unemployed', 'tableau']\n"
     ]
    }
   ],
   "source": [
    "#using content mmanager to open and read file\n",
    "with open(r'C:\\Users\\kats1\\Desktop\\Blacboard\\Python\\skills.txt', 'r', encoding=\"utf-8-sig\") as f:\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    contents = f.read()\n",
    "    tokenized_contents = word_tokenize(contents)\n",
    "    #removing the punctuations\n",
    "    tokenized_contents = filter(lambda x: x not in string.punctuation, tokenized_contents)\n",
    "    #removing stopwords \n",
    "    cleaned_content = filter(lambda x: x not in stop_words, tokenized_contents)\n",
    "    filtered_content = list(cleaned_content)\n",
    "    #getting rid of the duplicate elements in the list\n",
    "    nodup_filtered_content = list(set(filtered_content))\n",
    "    #print(type(nodup_filtered_content))\n",
    "print(nodup_filtered_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Uploading the text file to which the comparison needs to be made.\n",
    "- Performing the similar operation which is done above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "['critical', 'provide', 'believe', 'cause', 'development', 'root', 'new', 'organization', 'Degree', 'Self-driven', 'modify', 'operations', 'preferred', 'analytical', 'plus', 'behind', 'Strong', 'Business', 'sales', 'similar', 'skills', 'product', 'growth', 'Join', 'data', 'Science', 'experience', 'group', 'finance', 'consulting', 'decisions', 'key', 'SaaS', 'users', 'communicate', 'Excel', 'manner', 'Degrees', 'Economics', 'STEM', 'business', 'Technology', 'cross-functional', 'results', 'engineering', 'B2B', 'management', 'future', 'ways', 'mentioned', 'reports', 'Python', 'recommendations', 'happiness', 'code', 'maintain', 'identify', 'Collaborate', 'drive', 'intelligence', 'monitor', 'using', 'opportunities', 'scalable', 'years', 'metrics', 'R', 'efficient', 'Develop', 'power', 'Engineering', 'unlock', 'delivering', 'Inherently', 'Write', 'communication', 'analyses', 'ability', 'benchmarks', 'trends', 'background', 'frameworks', 'teams', 'curious', 'self-guided', 'marketing', 'committed', 'passionate', 'Build', 'fuel', 'people', 'Bachelors', 'fields', 'high', 'SQL', 'Excellent', 'regularly', 'senior', 'initiatives', 'facilitate', '2+', 'variance', 'strategic', 'Mathematics', 'dashboards', 'technology', 'Perform', 'work']\n"
     ]
    }
   ],
   "source": [
    "#open and read the text file\n",
    "with open(r'C:\\Users\\kats1\\Desktop\\Blacboard\\Python\\jobdesc.txt', 'r', encoding=\"utf-8-sig\") as f1:\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    contents_f1 = f1.read()\n",
    "    tokenized_contents_f1 = word_tokenize(contents_f1)\n",
    "    #removing the punctuations\n",
    "    tokenized_contents_f1 = filter(lambda x: x not in string.punctuation, tokenized_contents_f1)\n",
    "    #removing stopwords \n",
    "    cleaned_content_f1 = filter(lambda x: x not in stop_words, tokenized_contents_f1)\n",
    "    filtered_content_f1 = list(cleaned_content_f1)\n",
    "    #getting rid of the duplicate elements in the list\n",
    "    nodup_filtered_content_f1 = list(set(filtered_content_f1))\n",
    "    print(type(nodup_filtered_content_f1))\n",
    "print(nodup_filtered_content_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comaparing the 2 lists.\n",
    "### Goal:\n",
    "- compare the lists and return a list which contains the matching elements and the ones that are not in the 1st list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# writing a funtiion that returns the common elements after comparung the 2 lists.\n",
    "def compare(list1 , list2):\n",
    "    for elements in list1:\n",
    "        if elements in list2:\n",
    "            return elements\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'development'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare(nodup_filtered_content,nodup_filtered_content_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
