{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Purpose:\n",
    "- To scan the text file (my Resume in this case)<br>\n",
    "- To scan the text file (Job Description and resposibilities) that contains matching key words<br>\n",
    "- Return the count of matched keywords and return the missing keywords<br>\n",
    "- Use a list of technical keywords to extract the key words from the job text file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use nltk to fetch stopwords.\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import string\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filtering the text files.\n",
    "## Things to be done:\n",
    "- Converted the source files into CSV using Notepad++<br>\n",
    "- Open and read the csv files<br>\n",
    "- Tokenize the content (Converting each word & characters into individual tokens)<br>\n",
    "- Removing the punctuations (, . - \"white spaces\")<br>\n",
    "- Removing Stopwords (a, the , and, an , is........): Here you can find the entire list of stopwords https://gist.github.com/sebleier/554280<br>\n",
    "- Removing the duplicate elements from the list for more accuracy.<br>\n",
    "- Converting the elements into sets (aoids duplication by default)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'data analysis', 'css3', 'data visualization', 'leadreship', 'management', 'mysq', 'sql', 'articulate', 'business intelligence', 'requirement elicitation', 'plot', 'matplotlib', 'html5', 'prioratization', 'troubleshooting', 'teamwork', 'sequence diagram', 'identify user needs', 'oracle sql', 'uml diagrams', 'pandas', 'relational database', 'database', 'business analysis', 'surveys', 'interpersonal communication', 'design', 'user requirement', 'entity-relationship', 'clean', 'use-cases', 'state diagram', 'analytical thinking', 'anaconda', 'scenarios', 'ipython notebook', 'spyder', 'data modelling', 'project development', 'develop', 'identifying', 'logical data models', 'mysql', 'data models', 'data science', 'analytics', 'web development', 'team', 'php', 'analyze', 'data', 'data storage', 'jupyterlab', 'python', 'critical thinking', 'web design', 'numpy', 'tableau'}\n",
      "You have 58 skills\n"
     ]
    }
   ],
   "source": [
    "#using content mmanager to open and read file\n",
    "#converted the text file into csv file at the source using Notepad++\n",
    "#remmoved all the unecessary code for optimization.\n",
    "with open(r'C:\\Users\\kats1\\Desktop\\Blacboard\\Python\\skills.csv', 'r', encoding=\"utf-8-sig\") as f:\n",
    "    myskills = f.readlines()\n",
    "    #converting mall the string in the list to lowercase\n",
    "    #all the strings are converted to lowercase and split at ','.\n",
    "    list_of_myskills = [y.strip().lower() for x in myskills for y in x.split(',')]\n",
    "    set_of_myskills = set(list_of_myskills)\n",
    "    #print(type(nodup_filtered_content))\n",
    "\n",
    "#removing the empty element \n",
    "set_of_myskills.pop()\n",
    "print(set_of_myskills)\n",
    "len_mySkills = len(set_of_myskills)\n",
    "print(\"You have {skills} skills\".format(skills=len_mySkills))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'build', 'recommendations', 'code', 'results', 'sql', 'collaborate', 'benchmarks', 'intelligence', 'decisions', 'inherently', 'opportunities', 'plus', 'technology', 'new', 'perform', 'key', 'scalable', 'committed', 'cross-functional', 'senior', 'ways', 'believe', 'skills', 'facilitate', 'delivering', 'happiness', 'python', 'manner', 'science', 'group', 'efficient', 'variance', 'years', 'experience', 'consulting', 'metrics', 'sales', 'preferred', 'provide', 'regularly', 'stem', 'fields', 'degrees', 'development', 'join', 'product', 'fuel', 'develop', 'strong', 'cause', 'behind', 'business', 'unlock', 'curious', 'people', 'r', 'power', '2+', 'identify', 'frameworks', 'teams', 'background', 'critical', 'economics', 'mentioned', 'operations', 'analytical', 'monitor', 'finance', 'communication', 'dashboards', 'excel', 'users', 'mathematics', 'self-driven', 'trends', 'ability', 'degree', 'root', 'future', 'passionate', 'management', 'maintain', 'reports', 'engineering', 'organization', 'high', 'initiatives', 'analyses', 'write', 'self-guided', 'communicate', 'work', 'using', 'growth', 'similar', 'saas', 'marketing', 'b2b', 'excellent', 'modify', 'data', 'bachelors', 'drive', 'strategic'}\n",
      "There are 105 skills in the job requirement list\n"
     ]
    }
   ],
   "source": [
    "#open and read the text file\n",
    "with open(r'C:\\Users\\kats1\\Desktop\\Blacboard\\Python\\jobdesc.txt', 'r', encoding=\"utf-8-sig\") as f1:\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    contents_f1 = f1.read()\n",
    "    tokenized_contents_f1 = word_tokenize(contents_f1)\n",
    "    #removing the punctuations\n",
    "    tokenized_contents_f1 = filter(lambda x: x not in string.punctuation, tokenized_contents_f1)\n",
    "    #removing stopwords \n",
    "    cleaned_content_f1 = filter(lambda x: x not in stop_words, tokenized_contents_f1)\n",
    "    #all the strings are converted to lowercase and split at ','\n",
    "    filtered_content_f1 = [y.strip().lower() for x in cleaned_content_f1 for y in x.split(',')]\n",
    "    #getting rid of the duplicate elements in the list\n",
    "    set_of_job_skills = set(filtered_content_f1)\n",
    "    print(set_of_job_skills)\n",
    "    print(\"There are {skills} skills in the job requirement list\".format( skills= len(set_of_job_skills)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Uploading the text file to which the comparison needs to be made.\n",
    "- Performing the similar operation which is done above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hardware', 'merge', 'build', 'prototyping', 'solid', 'tasks', 'starting', 'understanding', 'oriented', 'experiences', 'databases', 'code', 'optimize', 'sql', 'integrating', 'internet', 'detail', 'process', 'methodology', 'help', 'desktop', 'ui', 'intelligence', 'administration', 'troubleshooting', 'research', 'configuration', 'break-fix', 'needs', 'diagrams', 'attention', 'technology', 'agile', 'flexibility', 'website', 'capabilities', 'monitoring', 'presentation', 'methods', 'improvement', 'support', 'utilizing', 'live', 'installation', 'interaction', 'amazon', 'environment', 'microsoft', 'customer', 'source', 'touch', 'mobile', 'usability', 'skills', 'services', 'improvements', 'leadership', 'processes', 'science', 'software', 'imports', 'virtualization', 'specifications', 'motivated', 'programming', 'experience', 'install,', 'metrics', 'file', 'review', 'server', 'big', 'engine', 'content', 'teamwork', 'visualizations', 'maintenance', 'implement', 'plan', 'strategy', 'principles', 'development', 'synchronize', 'building', 'emerging', 'recovery', 'product', 'logical', 'messaging', 'testing', 'design', 'networking', 'assurance', 'coding', 'technical', 'develop', 'audit', 'strong', 'prototypes', 'business', 'office', 'changes', 'configure', 'documentation', 'quality', 'architecture', 'motivation', 'end', 'security', 'identify', 'project', 'tech', 'user', 'migrating', 'hosting', 'deployment', 'input', 'optimizing', 'test', 'networks', 'protocols', 'interpersonal', 'time', 'critical', 'analysis', 'companyâ€™s', 'cloud', 'soft', 'queries', 'self', 'maintain,', 'deploying', 'servers', 'operations', 'analytical', 'database', 'flows', 'requests', 'with', 'impact', 'continually', 'technologies', 'communication', 'access', 'operating', 'visual', 'solutions', 'apis', 'repairs', 'team', 'storage', 'analytics', 'information', 'secure', 'analyze', 'system', 'performance', 'platforms', 'passwords', '(aws)', 'mining', 'open', 'recommend', 'management', 'maintain', 'problem', 'training', 'applications', 'workloads', '(qa)', 'organization', 'engineering', 'optimization', 'ux', 'interface', 'application', 'continuous', 'backup', 'languages', 'network', 'implementation', 'independently', 'tools', 'scalability', 'integrated', 'search', 'work', 'automation', 'writing', 'linux', 'wireframes', 'based', 'reporting', 'scenarios', 'modeling', 'user-centered', 'developer', 'web', 'existing', 'structures', 'computer', 'thinking', 'responsive', 'google', 'data', 'front', 'systems', 'integration', 'visualization', '(seo)', 'tablets', 'navigation', 'solving'}\n",
      "The number of elements in this list are: 213\n"
     ]
    }
   ],
   "source": [
    "\n",
    "    \n",
    "#open and read by line from the text file\n",
    "with open(r'C:\\Users\\kats1\\Desktop\\Blacboard\\Python\\list_of_skills.txt', 'r',encoding = 'utf-8') as f2:\n",
    "    #using readlines() instead of read(), becasue it reads line by line (each line as a string obj in the python list)\n",
    "    contents_f2 = f2.readlines()\n",
    "    #converting mall the string in the list to lowercase\n",
    "    list_of_skills = [y.strip().lower() for x in contents_f2 for y in x.split(' ')]\n",
    "    #removing stopwords\n",
    "    cleaned_content_f2 = filter(lambda x: x not in stop_words, contents_f2)\n",
    "    #converting into sets\n",
    "    set_of_skills = set(list_of_skills)\n",
    "    set_of_skills.difference_update({'\\ufeffassign','' '','to','into','/','it','of','for','and','on','a','the','in','desk'})\n",
    "print(set_of_skills)\n",
    "print(\"The number of elements in this list are: {mthd}\".format(mthd = len(set_of_skills)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comaparing the 2 sets.\n",
    "### Goal:\n",
    "- compare the sets and return a set which contains the matching elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to compare 2 sets.\n",
    "def set_compare(set1,set2):\n",
    "    comp = set(set1 & set2)\n",
    "    if(comp):        \n",
    "         print(\"THe match is: \", str(comp))\n",
    "    else:\n",
    "        print(\"No matching skills\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job skills VS set of Skills\n",
      "THe match is:  {'work', 'build', 'communication', 'management', 'maintain', 'code', 'critical', 'sql', 'experience', 'metrics', 'develop', 'strong', 'business', 'intelligence', 'engineering', 'organization', 'skills', 'science', 'data', 'development', 'technology', 'operations', 'analytical', 'identify', 'product'}\n",
      "<class 'NoneType'>\n",
      "My skill VS Skill required by the job\n",
      "THe match is:  {'sql', 'python', 'develop', 'management', 'data'}\n",
      "My Skills VS set of skills\n",
      "THe match is:  {'analytics', 'troubleshooting', 'design', 'teamwork', 'management', 'analyze', 'data', 'sql', 'scenarios', 'database', 'develop', 'team'}\n"
     ]
    }
   ],
   "source": [
    "    #comparing skills for the job with the list of skills\n",
    "    print(\"Job skills VS set of Skills\")\n",
    "   \n",
    "    \n",
    "    #Comparing my skills with the skills required for the job \n",
    "    print(\"My skill VS Skill required by the job\")\n",
    "    set_compare(set_of_myskills,set_of_job_skills)\n",
    "    \n",
    "    #cmparing my skills with the list of skills\n",
    "    print(\"My Skills VS set of skills\")\n",
    "    compare3 = set_compare(set_of_myskills,set_of_skills)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The scoring system.\n",
    "- it needs to return a percentage match after displaying the matched elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NoneType"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(compare1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
